[[enabling-fhc-access-centralized-logs]]
= Enabling `fhc` to Access Centralized Logs

To enable the `fhc admin logs syslogs` feature for searching platform logs by request IDs, configure `fh-supercore` to have access to Elasticsearch by following the steps in this section.

[NOTE]
--
If `fh-supercore` is not configured for access to Elasticsearch, running `fhc admin logs syslogs` yields an error message similar to the following:
....
FH-SUPERCORE-ERROR - Aggregated Logging is not enabled for this cluster.
....
--

. Enable centralized logging, as described in xref:enabling-centralized-logging[].

. Create a route to allow external access to Elasticsearch.

.. Log in to your OpenShift cluster
+
[source,bash]
----
oc login <url-of-openshift-master>
----

.. Select the existing logging project.
+
[source,bash]
----
oc project <logging-project-name>
----

.. Create a route to allow external access to Elasticsearch.
Replace the values in angle brackets as appropriate for your environment.
// TODO need more detail for the values
+
[source,bash]
----
oc create route passthrough --service=<elasticsearch-route-name> --hostname=<elasticsearch-hostname>.<openshift-master-hostname>
----

. Create a secret for `fh-supercore`.
+
To read from Elasticsearch, fh-supercore will use the existing Kibana
credentials. The existing Kibana certificate and key can be used. These
can be read from the existing secret and decoded.

.. Read the secret and output to JSON format.
+
[source,bash]
----
oc get secret logging-kibana -o json
----
+
This will output a base64-encoded representation of the certificate in "data.cert" and key in "data.key". We can now decode this and create a plain-text key and cert in our temp directory. Replace the output from
the above command into the commands below.

.. Decode the key and output to the `/tmp` directory or otherwise.
+
[source,bash]
----
echo "<contents-of-data.key>" | base64 --decode > /tmp/supercoreKey.key
----

.. Decode the certificate.
+
[source,bash]
----
echo "<contents-of-data.cert>" | base64 --decode > /tmp/supercoreCert.crt
----

.. Switch to the Core project.
+
[source,bash]
----
oc project <core-project-name>
----

.. Create a secret for `fh-supercore` that will use the Kibana credentials to perform searches.
+
[source,bash]
----
oc secrets new <core-secret-name> key=/tmp/supercoreKey.key crt=/tmp/supercoreCert.crt
----
+
A new secret is created in the core project called
`<core-secret-name>` as specified above.

. Update the deployment configuration of `fh-supercore`.

.. Open the editor for `fh-supercore` deployment configuration.
+
[source,bash]
----
oc edit dc fh-supercore
----

.. Set properties.
// TODO: THIS STEP NEEDS EXPLANATION
+
[cols="2*", options="header"]
|===
|Name
|Value

|`FH_ES_LOGGING_ENABLED`
|`true`

|`FH_ES_LOGGING_HOST`
|`https://<elasticsearch-hostname>.<openshift-master-hostname>`

|`FH_ES_LOGGING_KEY_PATH`
|`/etc/fh/es-keys/key`

|`FH_ES_LOGGING_CERT_PATH`
|`/etc/fh/es-keys/crt`

|`FH_ES_LOGGING_API_VERSION`
|`1.5` (_the version of Elasticsearch used by Openshift 3.2_)
|===
+
// TODO - WHAT IS THIS EXAMPLE SHOWING??? How is it related to the properties?
For example, if `<core-secret-name>` was `supercore-elasticsearch`
+
[source,yaml]
----
spec:
  template:
    spec:
      volumes:
        -
          name: supercore-elasticsearch-volume
          secret:
            secretName: supercore-elasticsearch
    containers:
      -
        name: fh-supercore
        volumeMounts:
          -
            name: supercore-elasticsearch-volume
            readOnly: true
            mountPath: /etc/fh/es-keys
----
